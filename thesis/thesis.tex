% !TeX encoding = UTF-f

%===============================================================================
% Font options are:
%   plain (default), serif (uses Palladio), sans-serif (uses Paratype Sans)
% Layout options are:
%   article (default, no chapters), book (for longer texts, offers \chapter)
% Paragraph options are:
%   noparskip (default, no spacing between paragraphs), parskip (spaced)
\documentclass[serif,article,noparskip]{agse-thesis}
\usepackage{amsmath}
\usepackage{subcaption}

% Global parameters, replace with actual values.
\newcommand{\thesisTitle}{The Rhythm of Relations of Color and Size: Detecting
Rectangles in Paintings created by Piet Mondrian}
% -> You may use \par (but not \\) to format the title. If you do so, you'll
%    need to manually set the 'pdftitle' attribute below.
\newcommand{\studentName}{Finn Pauls}
%===============================================================================

\hypersetup{pdftitle={\thesisTitle}}
\hypersetup{pdfauthor={\studentName}}

\begin{document}

\coverpage[
    student/id=4788442,
    student/mail=finn@inf.fu-berlin.de,
    thesis/type=Bachelorarbeit,            % optional, default: Bachelorarbeit
    thesis/group={Arbeitsgruppe Theoretische Informatik},
    thesis/advisor={Martin Skrodzki},           % optional
    thesis/examiner={Prof. Wolfgang Mulzer},
    thesis/examiner/2={Prof. Dr. Konrad Polthier}, % optional
    thesis/date=\today,                    % optional, default: \today
   %title/size=\LARGE,      % set this value to overwrite automatic font size
   % abstract/separate       % toggle this to move the abstract to its own page
] { The arrangement of compositional elements in abstract paintings by Piet
Mondrian have been of interest by researchers for a long time. Despite this
interest there are no publications examining these paintings numerically on a
broad pool of data. This thesis tries to change this by describing an algorithm
for detecting rectangles in Mondrian's compositions from 1920 to 1937. It also
provides a descriptive analysis of the resulting data. While there are no hints
that Mondrian used specific aspect ratios, a bias for positioning colors could
be revealed.}

\include{declaration}

\cleardoublepage

\tableofcontents

\cleardoublepage

\mainmatter

\section{Introduction}

\begin{figure}
\centering
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{images/B104.jpg}
  \caption{Composition II (1920)}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{images/B123.jpg}
  \caption{Composition with Red, Blue and Yellow (1930)}
  \label{fig:sub2}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=\linewidth]{images/B273.jpg}
  \caption{Opposition of Lines: Red and Yellow (1937)}
  \label{fig:sub3}
\end{subfigure}
\caption{Three examples of Mondrian paintings from 1920, 1930 and 1937}
\label{fig:mondrian}
\end{figure}

\subsection{Piet Mondrian}

The oeuvre of Piet Mondrian (1872-1944) consists of figurative paintings as well
as abstract compositions. Up until 1910 his works only depicted naturalistic
scenes like churches, trees, windmills or landscapes. From 1911 onwards his
paintings remain representational but are increasingly painted in a more
abstract way.

Around 1914 his compositions begin to be purely abstract and in 1917 he cofounds
the artistic movement and group \textit{De Stijl} also known as
\textit{Neoplasticism}. One of the primary objectives of the group is to reform
art by "abolishing natural form" \cite{wiki:manifest} altogether.

At some point around 1920 Mondrian further restricted his compositional elements
to rectangles and straight black lines. The lines were only allowed to run
horizontally or vertically. Only primary colors (red, blue and yellow) and
non-colors (black, white and grey) were allowed to be used. See Figure
\ref{fig:mondrian} for examples of Mondrian paintings with these elements.

Another founding member of \textit{De Stijl}, Georges Vantongerloo, used methods
inspired from mathematics for his compositions. One example of this is his
painting \textit{Composition Derived from the Equation y = -ax2 + bx + 18}.

Mondrian on the other hand is known to only use intuition when creating his
works, moving compositional elements for weeks, seeking a balanced composition,
until he was satisfied with the result.

Still many people have been interested in the question if Mondrian's
non-figurative paintings utilize certain compositional rules or techniques that
the painter might have used unconsciously. One approach that only became
feasible in the 1960s is to recreate art that resembles Mondrian's composition
using computers.

\subsection{Related Works}

There have been multiple attempts at creating art that resembles Mondrian's
compositions using computers. Feijs (2004) \cite{Feijs2004} presents different
techniques for generating images resembling non-figurative Mondrian paintings
from different periods. He concludes that different kinds of algorithms for
generating images can be used to formalise the distinction between different
types of Mondrian paintings.

Skrodzki and Polthier (2018) \cite{Skrodzki2018} use computer models to generate
Mondrian-inspired three-dimensional pieces using KdTree data structures. They
note however that while their results are similar to Mondrian paintings, they do
not always resemble Mondrian paintings since proportions are chosen randomly and
not deliberately.

There have been attempts to study the organisation and proportions of the
compositional elements used by Mondrian. In 1968 Hill \cite{Hill1968} analysed
the network topology of Mondrian's paintings. One of his findings shows the
avoidance of symmetry on a structural level. He also criticised earlier work for
inaccuracy of measurement and the lack of statistics and called for a more
substantiated analysis of the paintings.

Some sources \cite{bouleau1963,bergamini1980} suggest that Mondrian used golden
rectangles in his paintings. A golden rectangle is rectangle, where the ratio
between the sides length is the golden ratio $\phi \approx 1.618$. Other authors
however \cite{Livio2002,Markowsky1992} refuse those claims, finding fault with
the lack of evidence, which consists mostly just of exemplary superimposing
golden rectangles on paintings.

Despite this disagreement there have been very little attempts on actually
evaluating this question statistically. In a poster from 2017, Tanaka and
Miyanaga \cite{Tanaka2017} examine the use of rectangle ratios, specifically the
golden and silver ratio, in 10 late Mondrian paintings. They conclude that
Mondrian actually had a preference for the silver ratio $\delta_S \approx 2.414$ instead.

However to the authors knowledge there is no publication examining the question of
the use of certain special ratios on Mondrian's paintings with a larger data
set.

% TODO: Could also be in discussion?
% More motivational, could be easier done with our program
% http://faculty.philosophy.umd.edu/jhbrown/mondriansbalance/index.html#19
% "The lesson is that we must exploit digital technology to the full and set Mondrian's
% designs into the relevant space of possibilities if we are ever to put judgments
% of aesthetic balance on a firm footing â€“ which at present they are clearly not."
% "Such findings also suggest that we can put the formalist sector of aesthetic
% response on a firm footing only by much more extensive and rigorous
% experimentation with transforms of existing designs"

\subsection{Scope of the Thesis}

Providing numeric data to close the lack of foundation for analysis on the
neo-plastic compositions by Mondrian is the main objective of this thesis. The
goal is to create a program that uses methods of Computer Vision to extract the
compositional elements from images of the paintings. The program is restricted
to paintings from 1920 to 1937, which all use black lines to separate rectangles.

There are 178 works listed in the \textit{Catalogue Raisonn{\'e}}
\cite{joosten1998} of Mondrian for that time period. Of these works 150 were
paintings while the other 28 were sketches, unfinished works or plastic art. For
12 paintings, Mondrian used a tilted canvas, often referred to as
\textit{Diamond Compositions}. For the sake of simplicity these paintings were
excluded as well. Additionally 20 paintings in this source had either only a
greyscale image or no image available at all. These paintings were excluded as
well. The remaining 118 images were selected for the algorithm. They were
scanned and subsequently cropped so that only the painting and no frame was
visible. The images were scaled so that the longer side would be 1000 pixels.

Since the distinction between lighter grey to white and darker grey to black is
difficult even for a human observer, the detection of non-colors is restricted
to white and black only. Additionally the lines are simplified to not have any
thickness, so that they can be represented solely by their start and endpoints.

\section{Fundamentals} \label{fundamentals}

In this section I will specify the different definitions used for
conceptionalizing the program (\ref{definitions}). I am going to present
different existing methods and algorithms that were used (\ref{used}). Lastly I
am going to outline the concept for detecting the structure of rectangles in
Mondrians abstract paintings (\ref{concept}).

\subsection{Definitions} \label{definitions}

An Image $X$ with width $w$ and height $h$ is defined to be the set $I$. $$I =
\{p_{xy} | x \in \{1,2, \dots w\}, y \in \{1,2, \dots h\} \}$$ A RGB Image $I$
is an Image with the following  $p_{xy}$: $$p_{xy} = (r_{xy}, g_{xy}, b_{xy})
\in \{0,1,...,255\} \times \{0,1,...,255\} \times\{0,1,...,255\}$$ A Greyscale
image is an Image with $p_{xy} \in \{0,1, \dots 255\}$ and a Binary Image $B$ is
an Image with $p_{xy} \in \{0,1\}$, where we also refer to $0$ as \textit{black}
and $1$ as \textit{white}

\subsection{Used Algorithms and Methods} \label{used}

For preprocessing the images, a combination of methods are used: \textit{Image
Morphology}, \textit{Thresholding}, \textit{Contrast Limited Adaptive Histogram
Equalization (CLAHE)} and \textit{Masks}. These algorithms are provided by the
Python distribution of the Open Source library OpenCV \cite{opencv_library}.

\subsubsection{Image Morphology}

Image Morphology is based on Mathematical Morphology from the mathematical field
of set theory. For the purpose of this algorithm two basic morphological
operators are used. They are going to be explained descriptively here, without
going into detail of their mathematical definition. A more formal definition and
further reading can be found in Aguardo (2012) \cite{Aguardo2012}.

Given a binary image $B$ and a smaller binary image $B_s$ called the
\textit{Structuring Element}, with a dedicated center point $c \in B_s$, two
basic operations can be applied: Erosion and Dilation.

\textit{Erosion} $B \ominus B_s$ is equivalent to iterating through all of the white
pixels of $B$ and turning them black if not all of the points of $B_s$
translated by its center point $c \in B_s$ are also white in $B$. Therefore the
white areas in $B$ are reduced. \cite{Smith1997}

Similarly the \textit{Dilation} operation  $B \oplus B_s$ translates the center
point of the Structuring Element to every pixel $p \in B$. For each of these
pixels all the neighbouring pixels that intersect with the translated $B_s$ are
turned white. The total area of white pixels is increased. \cite{Smith1997}

Image Morphologies have multiple uses like increasing certain areas for better
recognition or separating larger shapes of an image. In this case they will be
helpful for correcting interruptions in the black lines of the image as well as
for separating black areas that are bigger than typical lines.

\subsubsection{Thresholding}

Thresholding $T(G) = \{t_{xy}\ \in \{0,1\} | g_{xy} \in G\}$ is a process for turning a greyscale image $G$
with pixels $g_{xy}$ into a binary image $B$ using a threshold $t \in
0,1,\dots255$. Each pixel $t_{xy}$ is assigned a black or white value given
whether it is below or above the threshold.

\begin{equation}
  t_{xy} =
  \begin{cases}
    0 & \quad  \text{if}  \quad g_{xy} \leq t\\
    1  & \quad \text{if}  \quad g_{xy} > t
  \end{cases}
\end{equation}

It is usually used to separate out regions of interest in an image. For this
application these regions will be the black lines of the painting.

\subsubsection{Contrast Limited Adaptive Histogram
Equalization (CLAHE)}

A \textit{Histogram} of an image is the distribution of brightness values in an
image. \textit{Histogram equalization} is the process of adjusting the contrast
of an image using the Histogram. Global histogram equalization changes the
brightness of each pixel in the image using the overall histogram of the image.
\cite{ShapiroLindaG2001Cv}

\textit{Adaptive histogram equalization (AHE)} on the other hand only uses the
histogram of a specified area around any given pixel to adjust its brightness. It
therefore is able to better increase the local contrast.

However \textit{AHE} tends to overamplify noise in an image. Fairly uniform
regions of the same brightness have high histogram pieaks and are turned into
noisy patterns.  \textit{Contrast Limited Adaptive Histogram Equalization
(CLAHE)} limites this effect by setting a maximum value for the values of the
histogram. \cite{Pizer1987}

\subsubsection{Masks}

Masks operations are similar to elementary arithmetics. Each pixel $a_{xy}$ in
one image  $X_a$ is added, substracted, multiplied or divided with $b_{by}$ of
another image $X_b$. For example the operation $X_a + X_b$ denotes the set
$$X_a + X_b = \{\mathrm{min}(255, p_{xy} + q_{xy}) | p_{xy} \in X_a, q_{xy} \in X_b\}$$

An additional operation on a binary image $B_a$ is the opposite or inversion
$\neg B_a$, which is equivalent to a bitwise not.
$$\neg B_a = \{\mathrm{max}(0,p_{xy} - 1) | p_{xy} \in B_a\}$$

\subsection{Concept} \label{concept}

The aim for the detection algorithm is to take a cropped Mondrian painting as
an input and detect all the rectangles in it as well as their colors.

The input is an RGB Image $I_1$ of a Mondrian painting. The expected output is a
list of rectangles with their position, sizes and color as they are
compositionally seen in the painting. All rectangles combined are expected to
exactly cover the area of the input image in a way that the original could be
dissected into this set of rectangles. The thick black lines in the paintings
are seen as one-dimensional lines that are positioned in the middle of the
detected thicker lines.

The algorithm itself can be separated into two different phases: Image
preprocessing (\ref{preprocessing}) and the recognition of rectangles (\ref{rectangles}).

The goal of the first preprocessing phase is to obtain a binary image in which
black represent the lines of the painting while white represents the inner area
of the rectangles. The different steps of the preprocessing phase are visualized
in Figure \ref{fig:preprocessing}.

The second phase then takes this binary image and returns a list of found
rectangles. Additionally, for recognizing the colors of the rectangles, the
original input image is used.

\subsubsection{Image preprocessing} \label{preprocessing}

\begin{figure}
  \includegraphics[width=\linewidth]{images/preprocessing_steps.png}
  \caption{Preprocessing Steps on \textit{Composition II in Red, Blue, and Yellow
  from 1929}}
  \label{fig:preprocessing}
\end{figure}

At first, a Gaussian blur is applied to the input RGB Image $I_1$ to reduce
artifacts that the input images might include, the result of the blur is $I_2$.
These artifacts might be craquelure or fading of darker areas in the paintings.
But they might also be results of the photography and scanning the images.

Next, the RGB input image is decomposed into a Greyscale Image $G_1$ by using
the maximum value of the RGB triplet for each pixel in $I_2$:
\begin{equation}
G_1 = \{p_{xy} \in \{0,\ldots,255\} \mid (r_{xy},g_{xy},b_{xy})\in I_2\text{ and }p_{xy}=\max\{r_{xy},g_{xy},b_{xy}\}\}\\
\end{equation}

To normalize the brightness distribution of $G_1$ and increase the contrast of
the darker regions, we now apply histogram equalization to $G_1$. For this we
use \textit{Contrast Limited Adaptive Histogram Equalization (CLAHE)}. In
contrast to non-adaptive and ordinary adaptive histogram equalization
algorithms, this prevents the overamplification of noise as reasoned above. The
the result of the equalization is called $G_2$. \cite{Pizer1987}

After the normalization is applied, colorful areas of the image are further
brightened to make them stand out against the black areas of the paintings. This
way, for example, darker blue areas can be better distinguished from black
areas. Since the difference between the maximum values $G_1$ and the minimum
value $G_{min}$ of the RGB triplet is related to the colorfulness of a pixel, we
calculate this for every pixel of the input image. The resulting Mask $G_c$ from
this calculation is added to the contrast-normalized image $G_3$:
\begin{align}
G_{min} &= \{p_{xy} \in \{0,\ldots,255\} \mid (r_{xy},g_{xy},b_{xy})\in I_2\text{ and }p_{xy}=\min\{r_{xy},g_{xy},b_{xy}\}\}\\
G_c &= G_1 - G_{min}\\
G_3 &= G_2 + G_c
\end{align}

Now the image $G_3$ with the elements $g_{xy}$ is converted into a binary image
using Thresholding $B_1 = T(G_2)$. The threshold value $t$ needs to be chosen as
such as it is optimally separating between the darker lines and the lighter
rectangles in the image. See \ref{parameter} for how that value was determined
in praxis.

Since the thresholding step might leave some interruption in the black lines,
the white areas of the image are reduced: An Erosion $B_2 = B_1 \ominus B_e$ is
applied. In this case, the structuring element $B_e$ is a $N\times N$ binary
Image. Using the Erosion some accidental interruptions in the lines can be
restored. However choosing a Structuring Element that is too big, might result
in loss of information by filling smaller white rectangles black. Therefore the
size $N$ needs to be chosen carefully.

The resulting image $B_2$ now separates the darker parts of the image fairly
well. However, the goal is to detect black lines, but Mondrian paintings also
include filled black rectangles. To remove these black rectangles, we create a
mask that applies a Dilation $B_m = B_2 \oplus B_d$ with a larger Structuring
Element $B_d$ ($M\times M$) compared to $B_e$ on the image. The size of $B_d$ is chosen in a
way that most of the lines in the paintings are removed, only leaving inner
areas of black rectangles. The inverse of the resulting mask $B_m$ is then
removed from the image of the last step $B_3 = B_2 - B_m$. Hence only the
outlines of the black rectangles, as well as the black lines, remain in $B_3$.
This is the output of the first phase.

\subsubsection{Detection and recognition of rectangles} \label{rectangles}

Since the rectangles in the painting are defined by the horizontal and
vertical lines in the image, the detection starts by finding all of those lines
in the output binary image $B_3$ from the previous phase.

Now all uninterrupted vertical sequences $V$ and horizontal sequences $H$ of
black pixels with a minimum length $\ell$ are considered. You can think of it as
a lossy run-length encoding once horizontally and once vertically. The selection
of the parameter $\ell$ is discussed in \ref{parameter}.

However, this means that for every structural line in the painting, multiple
line segments are recognized. For example, a line that is 50 pixels wide would
be recognized as 50 lines. Therefore as a next step parallel lines close to each
other are merged into a single line. As long as parallel lines are within a
certain distance $d$ from each other, they are merged into one line. For
horizontal lines, the resulting line will have the average $y$ value of all
those lines and the minimum and maximum $x$ values as starting and end points.

From our conceptional view on Mondrian paintings, the ends of lines always touch
another line or the edge of the painting. However, the lines that we reduced now
might overlap slightly or not even connect to the next line.

Now consider the two ends of every horizontal line $h \in H$. For each end $e =
(x_e,y_e)$ find the closest vertical line $v \in V$ that could touch $e$ by
only translating it horizontally.

Since a rectangle is defined by the black lines in the paintings as well as the
edges of the painting, the lines of the edges to the $H$ and $V$ are added as
well.

All lines should now represent the structure of the painting. The desired output
though is a list of rectangles. Every rectangle in the image can be defined
through a set of four different corners: top-left, top-right, bottom-left and
bottom-right. These corners are always intersections of two lines, either fully
crossing or touching (T-crossing). The corners and their types can be
identified.

After this, four different corners are combined into a rectangle by finding
matching corners. This is done by iterating through the top-left corners $(x,y)$
and finding the closest top-right corner to the right $(x_r, y)$ and the
closest bottom-left corner below $(x, y_b)$. The rectangle is then defined by
the position of the top-left corner and its width and height
$(x,y,x_r-x,y_b-y)$.

The colors are determined for each rectangle in the list. For this purpose, the
rectangle is clipped from the original image $I_1$ and the average color of the
selection is calcualted. This color is then reduced to either black, white, red,
blue or yellow.

\section{Implementation} \label{implementation}

This section describes implementation of the above-described concept. First
thehow structure of the software is presented (\ref{structure}), then challenges
in performance are discussed (\ref{performance}) and finally the choosing of the
parameters (\ref{parameter}) is explained.

The algorithm was implemented in Python 3.7 using the \textit{OpenCV 3.4.1} and
\textit{NumPy 1.15.2} libraries. OpenCV provided the different image processing
methods described in \ref{used} as well as other methods for reading, writing
and manipulating image files. NumPy, which is part of the SciPy package, is a
package for scientific numerical computing \cite{scipy}.

\subsection{Structure} \label{structure}

\begin{lstlisting}[otherkeywords={function,input\:,output\:},label=lst:program,caption=Flow and structure of the program]
input:
  directory d,
  threshold t,
  erosion kernel size N,
  dilation kernel size M,
  minimum line length l,
  maximum line width d,

for every file f in d,
  read original image from file f
  binary = preprocessing(original)
  output = detect_rectangles(binary, original)
  check_image = create image from output and overlay it on original
  write check_image to disk
  write output to json file

function preprocessing
  input: RGB image of a Mondrian painting image_1
  output: Binary image where only the lines are black

  image_2 = blur(image_1)
  r,g,b = split_channels(image_2)
  grey_1 = max(r,g,b)
  grey_min = min(r,g,b)
  grey_2 = clahe(g1)
  grey_c = grey_1 - grey_min
  grey_3 = grey_2 + grey_c
  binary_1 = threshold(grey_3, t)
  binary_2 = erode(binary_1, N)
  binary_m = dilate(binary_1, M)
  binary_3 = binary_2 + bitwise_not(dilated)
  return binary_3

function detect_rectangles
  input:
    Binary image where only the lines are black binary_image,
    Original RGB image of that painting original_img
  output: List of rectangles and their colors, dimensions and positions

  (h1, v1) = detect_lines(binary_image, l)
  (h2, v2) = reduce_lines(h1, v1, d)
  (h3, v3) = remove_lines_close_to_border(h2, v2)
  (h4, v4) = add_border_lines(h3, v3)
  (h5, v5) = connect_lines(h4, v4)
  (tl, bl, br, tr) = find_corners(h5, v5)
  rects = find_rectangles(tl, bl, tr))
  rects_with_color = find_colors_for_rects(rects, original_img)
  return rects_with_color
\end{lstlisting}

The program sketched out in Listing \ref{lst:program} takes a directory and the
different parameters as an input. The main algorithm was implemented in two
functions \texttt{preprocessing} and \texttt{detect\_rectangles}. The program
reads the list of images from the input directory and feeds them into
\texttt{preprocessing} to get a binary image. That binary images is then
analyzed by \texttt{detect\_rectangles} to get a list of rectangles.

\begin{figure}
\begin{minipage}{0.2\textwidth}
  \includegraphics[width=\linewidth]{images/B244.jpg}
\end{minipage}
\begin{minipage}{0.8\textwidth}
\begin{lstlisting}
{
  "id": "B244",
  "height":1000,
  "width":489,
  "rectangles":[
    {"x":294,"y":91,"w":195,"h":691,"c":"white"},
    {"x":294,"y":782,"w":195,"h":218,"c":"white"},
    {"x":64,"y":0,"w":230,"h":1000,"c":"white"},
    {"x":294,"y":0,"w":195,"h":91,"c":"blue"},
    {"x":0,"y":0,"w":64,"h":1000,"c":"white"}
  ]
}
\end{lstlisting}
\end{minipage}
\caption{Source image and \textit{JSON} representation for \textit{Composition no. I (1934)}}
\label{fig:json}
\end{figure}

Then the result of \texttt{preprocessing(image)} is used as the input for
\texttt{detect\_rectangles}. This function executes the steps described in
\ref{rectangles}. The result is a list of rectangles and their respective
dimensions, colors and positions. An image is created from the resulting data
and overlaid over the original image and saved to disk. This can be used to
validate the result of the algorithm. The data from the rectangles is encoded in
a \textit{JSON} file for each image. \textit{JSON} was chosen, since it is a
widespread flexible data-interchange format that is also human-readable. An
example for such a \textit{JSON} file can be seen in Figure \ref{fig:json}.

At first \texttt{detect\_rectangles} uses \texttt{detect\_lines} to extract a
list of all vertical and horizontal pixel lines from the preprocessed image.
Then \texttt{reduce\_lines} combines parallel lines that are next to each other
into a single line. It iterates through the items in the list and looks for
neighbouring lines by iterating in another nested loop through the same list. If
a matching line is found, the line is removed from the list, so that it will not
appear in the iteration again. The loose ends of the lines are then connected by
\texttt{connect\_lines}.

As an example Listing \ref{lst:findrectangles} shows the source code of
one of the functions \texttt{find\_rectangles}, which finds rectangles from a
list of top-left, bottom-left and top-right positions. The length of each of
these lists is the same and is expected to be the number of rectangles. The
program first sorts the top-right corners by their x position and the
bottom-left corners by their y position. When iterating through the top-left
corners, we know that their x position is going to be the same as the matching
bottom-left corner \texttt{bl}, but a larger y-coordinate. So we only select
these candidates from the \texttt{bottom\_left} list using an iterator
expression. Since we ordered the corners before from top to bottom, we know the
matching corner is going to be the first returned by the iterator. We therefore
only call the iterator once with \texttt{next}. The same logic is applied to
bottom-left corners. Using the coordinates of the matching top-right and
bottom-left corners, the rectangle is calculated and added to a list of
rectangles as a tuple. That list is then returned by the function.

\begin{minipage}{\linewidth}
\begin{lstlisting}[otherkeywords=def,label=lst:findrectangles,caption=Function for constructing rectangles from corners]
def find_rectangles(t_l, b_l, t_r):
    t_r.sort(key=lambda pos: pos[0])
    b_l.sort(key=lambda pos: pos[1])
    rectangles = []
    for x,y in t_l:
        x2,_ = next(c for c in t_r if c[1] == y and c[0] > x)
        _,y2 = next(c for c in b_l if c[0] == x and c[1] > y)
        w = x2 - x
        h = y2 - y
        rectangles.append((x,y,w,h))
    return rectangles
\end{lstlisting}
\end{minipage}

\subsection{Line Detection}

Using a custom algorithm for the line detection was not the first choice. First
a commong technique, the Hough Transform, was used. Hough Transforms rotate a
line over every pixel of an image with an angle $\theta$ for every step. For
each rotation white pixels on that lines are used as votes for that line. Then
lines above a certain threshold of votes are considered. Using $\theta =
\frac{\pi}{2}$ to only consider horizontal and vertical lines, this method did
not give accurate enough results. The algorithm would for example sometimes
detect a vertical line between two close horizontal ones. Since we did not
expect gaps between lines after our preprocessing, this method did not fit.

It became clear that it would be simpler and more accurate to construct the
lines by iterating through the image. To find horizontal lines $H$ from
\ref{rectangles}, the image is scanned vertically line by line. The
iteration runs through the pixels of each horizontal line. Uninterrupted
sequences of black pixels are added to a list of horizontal lines. Only
sequences with a specified minimum length $\ell$ are added. The minimum length
should be slightly larger than the maximum width of the lines in the image.
Vertical lines $V$ are recognized respectively by iterating through the lines
from left to right.

\subsection{Iterative approach}

The different processing steps of the algorithm are visualized by providing
multiple output images for each input image. These images allow an inspection of
the different intermediary results created in the process. Additionally an image
was created superimposing the detected rectangle over the input image. This was
mainly used review the correctness of the result.

This visual feedback gave insights into problems of the algorithm like small
bugs or conceptional problems. For example the preprocessing step to increase
the brightness of areas that are more colorful was introduced because there were
issues of discriminating darker blue areas from black ones. This way the
development of the algorithm could follow an iterative approach.

These images also provided a basis for the adjustment of the parameters of the
different steps.

\subsection{Parameter Selection} \label{parameter}

By running the program on the images and looking at the output images for the
different steps, the reasonable values for the parameters of the program can be
determined.

By running the program and looking at the results of the Thresholding for each
image, comparing it to the input image, the threshold value $t = 110$ was
determined to give reasonable results.

To better fine-tune the parameters, we selected a subset of input images and
always manually changed these parameters until the result was correct. The
resulting \textit{JSON} files with the correct results were moved to another
directory \textit{detected}. Then a step was added to the program that would
always compare the computed result with the data in that directory if available.
When the result differed, it would print out a warning.

Using this output the minimum length $\ell$, the maximum width $d$ and the size
of the erosion kernel $N$ as well as the dilation kernel $M$ were changed to
maximize the number of recognized images from that set. The resulting parameters
were $l = 60$, $d = 70$, $N=11$ and $M =40$.


\subsection{Performance} \label{performance}

The performance of the algorithm was measured by timing the duration for each
image. The first implementation of the algorithm took about 1100 milliseconds per
iteration. By running timings on different parts of the processing, the
\texttt{detect\_lines} function was discovered as a bottleneck. It was
accountable for about 93 percent of the processing time.

This was the only place in the program were we iterated through all of the pixels
in the image using Python. All other operations were done using OpenCV or NumPy.
They also iterate through all of the pixels but using optimized C code.

To reduce the time of this step we decided to reimplement this function in a
compiled, more low-level language. We chose to use Rust using the \textit{rust-cpython}
library for bindings. Using the same algorithm implemented in Rust, the time of
this step was reduced from about 1020 to 40 milliseconds. The runtime of the
program could be reduced by a factor of 13.

This time could have been be further reduced by running multiple parallel
iterations over the different rows or colums. However for our purpose the
achieved time was sufficient.

\subsubsection{Evaluation of Tools}

Reflecting about the used tools, OpenCV would certainly be chosen again. It
supports a variety of established computer vision algorithms, is well documented
and has a variety of learning resources. Since OpenCV primarily supports C++ and
Python interfaces, the programming language choice was one of these options.
While using the compiled language C++ could have increased performance over the
interpreted Python, it would also have decreased productivity. Python's
readibility and user-friendly data-structures made it a good choise for an
iterative development.

% !TeX encoding = UTF-8
\section{Results} \label{results}

 All 118 images were processed by the detection program and subsequently checked
 for accuracy by comparing the result with the original. The resulting dataset
 consists of 1316 rectangles and their respective size, colors, and paintings.

Some explorative analysis about the use of color (\ref{color}) and ratios
(\ref{ratios}) was performed.

\subsection{Colors} \label{color}

On average Mondrian paintings consist of 79.7\% non-colors (black, white) and
20.3\% colors (red, blue, yellow) ($\sigma = 17.0\%$), see Figure
\ref{fig:colors-noncolors}. The median percentage of each color appears to be
rather similar, the distribution of red however is more widespread as you can
see in Figure \ref{fig:colors-rby}.

\begin{figure}
\includegraphics[width=\linewidth]{images/colors-non-colors.png}
\caption{Evident preference of non-colors in the paintings}
\label{fig:colors-noncolors}
\end{figure}

\begin{figure} \includegraphics[width=\linewidth]{images/colors-rby.png}
\caption{Median proportion of the colors are very similar, red however has a
wider distribution} \label{fig:colors-rby} \end{figure}

To see if different colors of rectangles have overall preferred positions in the
compositions, we assembled a dataset of all rectangles and their respective
positions, width and colors. We calculated the centers of all of these
rectangles and plotted them by color. We also visualized the estimated
probability density function of the positions using Kernel density estimation
with an Gaussian kernel selected by Scott's method \cite{Terrell1992}. The
result is given in Figure \ref{fig:kde}. The first thing noticable is that the
color red appears to have a substantial bias to the top-left corner. Similarly
blue has a bias to the bottom-right corner, but is comparatively more evenly
spread.


\begin{figure}
\includegraphics[width=\linewidth]{images/kernel-densities.png}
\caption{Scatter plots and KDE for each color}
\label{fig:kde}
\end{figure}

\subsection{Ratios} \label{ratios}

For all rectangles we calculated the aspect ratio of the longer to the shorter
side. Figure \ref{fig:aspect-rects} shows the estimated probability density of
the ratios in Mondrians rectangles compared to the ratio of a set of 10000
random rectangles. Figure \ref{fig:longer-x-shorter} shows all rectangles
plotted by their sides as well as lines for certain proposed ratios. The data
does not show peaks for the golden or silver ratio. This supports the rejection
by Livio (2002) \cite{Livio2002} and Markowsky (1992) \cite{Markowsky1992} of
the golden rectangle claim by Bouleau (1963) \cite{bouleau1963} and Bergamini
(1980) \cite{bergamini1980}.

\begin{figure}
\includegraphics[width=\linewidth]{images/aspect-max-min-rects.png}
\caption{There appears to be no difference between randomly generted rectangles and rectangles used by Mondrian.}
\label{fig:aspect-rects}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{images/longer-x-shorter.png}
\caption{Rectangles longer side to shorter side}
\label{fig:longer-x-shorter}
\end{figure}


% TODO: Number of rectangles over time?
% TODO: How many paintings use all colors? How many with only one?

% !TeX encoding = UTF-8
\section{Discussion} \label{conclusion}

The developed program is able to detect rectangles in a class of abstract
Mondrian paintings. Human control and intervention are still necessary to make
sure the result is correct. By adjusting the input parameter or in some cases
manually editing the input images, all images were detected successfully. From
the dataset of all chosen images 76\% of the images could be detected without
manual intervention.

A first look at the resulting data showed some interesting finding that deserves
further investigation. The dataset that we obtained from the images will be made
freely available for other applications, from statistical analysis to machine
learning.

The data does not suggest a preferred use of the golden or silver ratio in
rectangles. There only seems to be a general tendency towards squares.
Justifying continued research into this direction should depend on findings in
the psychology of aesthetics. So far the studies about the visually pleasing
nature of golden rectangles appear to contradict each other. Perceptional
studies about the silver ratios are missing entirely. However, research in  ratios
of other components, like the positioning of lines or the size of rectangles to
each other might lead to interesting results.

In "Art and Visual Perception" Rudolf Arnheim \cite{Arnheim1965} notes that "an
object in the upper part of the composition is heavier than none in the lower;
and location at the right side makes more weight than location on the left."
Winner (1987) \cite{Winner1987} psychologically tested these principles by
showing abstract images and their horizontally or vertically flipped
counterparts. Their findings support the up-down-principles, but not the
left-right-principle.

Arnheim also notes that the color red is heavier than the color blue. A study
from \cite{Locher2005} found some support for this claim when showing
design-trained participants modified Mondrian paintings were some colors were
swopped.

It would be interesting to explore if the found preference by Mondrian to use
red in the top-left corner could be explained by a combination of these proposed
principles of balance or whether it is merely coincidental or habitual.


% Do digital idealized representation of Mondrian paintings are comparable
% to the actual paintings in terms of certain factors like perceptional balance

% TODO: Big is heavier than small (i think)

% More generally: More paintings by Mondrian, other artists of De Stijl and
% artists in general

% Color distribution numbers close to Pareto's Principle. Maybe 80% of the
% effect of the painting stem from the 20% of the colors. Psychological research?
% eye-tracking studies

\bibliography{bibliography}

% \appendix
% \include{5_appendix}

\end{document}
